{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b9bf3b",
   "metadata": {},
   "source": [
    "# **Quantitative assessment of clearing protocols**\n",
    "### Written by Deniz Bekat (*deniz.bekat@crick.ac.uk*)\n",
    "\n",
    "\n",
    "### This programme is a semi-automated, easy-to-use workflow designed to assess multi-dimensional fluorescence images and produce quantitative parameters so **you** can make a decision on which clearing protocol is best for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91440210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "#image and metadata import\n",
    "from bioio import BioImage\n",
    "import bioio_bioformats\n",
    "import bioio_ome_tiff\n",
    "\n",
    "# data processing and computation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import binary_fill_holes, distance_transform_edt\n",
    "from skimage import io, morphology, measure, filters, restoration\n",
    "from cellpose import models\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# data visualisation and saving\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tifffile as tf\n",
    "\n",
    "#file handling\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049f54e",
   "metadata": {},
   "source": [
    "## **Importing your image and its metadata**\n",
    "\n",
    "#### Here, we are going to import your image into the Python script using the `bioio` library: this uses a function called `BioImage` to import your image and all the relevant metadata for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb4cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_read = BioImage(\"/nemo/project/proj-omero/omero-import/janseng/omero_transferred/20251117_CAL127-2B2_10X_0-4NA_ECi_1/20251117_CAL127-2B2_10X_0-4NA_ECi_1_MMStack_Pos0.ome.tif\") # this will read your image file based on the relative path and your image file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d732e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# producing the metadata of your image\n",
    "\n",
    "print(im_read.dims)\n",
    "\n",
    "x_res = im_read.physical_pixel_sizes.X\n",
    "y_res = im_read.physical_pixel_sizes.Y\n",
    "z_res = im_read.physical_pixel_sizes.Z\n",
    "\n",
    "ani = round(z_res / x_res, 2)\n",
    "\n",
    "print(f\"Resolution of X (µm): {im_read.physical_pixel_sizes.X}\")\n",
    "print(f\"Resolution of Y (µm): {im_read.physical_pixel_sizes.Y}\")\n",
    "print(f\"Resolution of Z (µm): {im_read.physical_pixel_sizes.Z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_read.standard_metadata # some extra information on the metadata of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fd296",
   "metadata": {},
   "source": [
    "#### For most of this analysis, we want to mainly use the **nuclear channel** - we can introduce another variable here called `im_nuclear` that holds only the nuclear channel.\n",
    "\n",
    "#### NOTE: only do this if your sample has multiple channels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear_channel_no = 3 # enter the channel number of your nuclear marker here - don't forget that Python starts counting at 0!\n",
    "\n",
    "if im_read.standard_metadata.image_size_c > 1:\n",
    "    im_nuclear = im_read.data[0][nuclear_channel_no]\n",
    "else:\n",
    "    im_nuclear = im_read.data[0][0] #im_nuclear becomes a numpy array, removing the time and channel dimensions since they are unused\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a5f5d9",
   "metadata": {},
   "source": [
    "## **Visualising your image**\n",
    "\n",
    "#### *Looking* at your data is a crucial step, to check everything is working, and that you're seeing what you expect. Here's a quick visualisation of your image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some z slices to display the data throughout\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 8))\n",
    "\n",
    "axs[0, 0].imshow(im_nuclear[int(im_nuclear.shape[0] / 7),], cmap='gray')\n",
    "axs[0, 0].set_title(f'Z={int(im_nuclear.shape[0] / 7)}')\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "axs[0, 1].imshow(im_nuclear[int(2* im_nuclear.shape[0] / 7),], cmap='gray')\n",
    "axs[0, 1].set_title(f'Z={int(2* im_nuclear.shape[0] / 7)}')\n",
    "axs[0, 1].axis('off')\n",
    "\n",
    "axs[1, 0].imshow(im_nuclear[int(3 * im_nuclear.shape[0] / 7),], cmap='gray')\n",
    "axs[1, 0].set_title(f'Z={int(3 * im_nuclear.shape[0] / 7)}')\n",
    "axs[1, 0].axis('off')\n",
    "\n",
    "axs[1, 1].imshow(im_nuclear[int(4 * im_nuclear.shape[0] / 7),], cmap='gray')\n",
    "axs[1, 1].set_title(f'Z={int(4 * im_nuclear.shape[0] / 7)}')\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "axs[2, 0].imshow(im_nuclear[int(5 * im_nuclear.shape[0] / 7),], cmap='gray')\n",
    "axs[2, 0].set_title(f'Z={int(5 * im_nuclear.shape[0] / 7)}')\n",
    "axs[2, 0].axis('off')\n",
    "\n",
    "axs[2, 1].imshow(im_nuclear[int(6 * im_nuclear.shape[0] / 7),], cmap='gray')\n",
    "axs[2, 1].set_title(f'Z={int(6 * im_nuclear.shape[0] / 7)}')\n",
    "axs[2, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204a407",
   "metadata": {},
   "source": [
    "## **Measuring statistical parameters**\n",
    "\n",
    "#### Uncleared samples, due to light scattering, can degrade in intensity and in the contrast of the image. To measure this, we measure the mean and standard deviation per unit depth using `numpy`.\n",
    "\n",
    "#### To do this, we analyse each 2D slice of the image, where we:\n",
    "- ##### Identify the areas of the image where the sample is present, using thresholding algorithms `skimage.filters` - this lets us create a **binary mask**.\n",
    "- ##### Measure the mean and standard deviation using `np.mean()` and `np.std()` for parts of the image identified as sample\n",
    "- ##### Save those values, along with the relevant dimension in Z, to track **how these values change with depth**\n",
    "\n",
    "#### We can then compare the results from different samples to compare their properties!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35052aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measuring properties per image slice; plot across z to see how properties change with image thickness\n",
    "mean = []\n",
    "standard_dev = []\n",
    "\n",
    "\n",
    "for z in range(0, len(im_nuclear)): #checks through every slice\n",
    "    \n",
    "    slice = im_nuclear[z]\n",
    "    \n",
    "    slice_thresh = filters.threshold_li(slice)\n",
    "    slice_bin = slice >= slice_thresh\n",
    "\n",
    "    mean_val = np.mean(slice[slice_bin > 0])\n",
    "    std_val = np.std(slice[slice_bin > 0])\n",
    "\n",
    "    mean.append(mean_val)\n",
    "    standard_dev.append(std_val)\n",
    "    \n",
    "\n",
    "step_size_Z = im_read.physical_pixel_sizes.Z #change depending on the step size of the acquired image\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Slice\": np.arange(len(mean)) + 1,\n",
    "    \"Mean Intensity\": mean,\n",
    "    \"Std Dev\": standard_dev\n",
    "})\n",
    "\n",
    "df['Imaging depth'] = df['Slice'] * step_size_Z\n",
    "df['Clearing'] =\"ECi\" # this is the KEY PART! change this to whichever clearing protocol you're using!\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ecb401",
   "metadata": {},
   "source": [
    "## **Normalising results**\n",
    "\n",
    "#### Since the raw pixel intensity values can differ between samples, microscope system, or stain, we must *normalise* the data to be able to compare different images together.\n",
    "#### Here we introduce some functions that will normalise the mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation\n",
    "\n",
    "def normalise_mean(df): # mean intensity normalisation\n",
    "\n",
    "    dmin = np.min(df['Mean Intensity'])\n",
    "    dmax = np.max(df['Mean Intensity'])\n",
    "\n",
    "    df['Normalised Mean'] = 100 * (df['Mean Intensity'] - dmin) / (dmax - dmin)\n",
    "\n",
    "    return df\n",
    "\n",
    "def normalise_std(df): # standard deviation normalisation\n",
    "\n",
    "    dmin = np.min(df['Std Dev'])\n",
    "    dmax = np.max(df['Std Dev'])\n",
    "\n",
    "    df['Normalised Std Dev'] = 100 * (df['Std Dev'] - dmin) / (dmax - dmin)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a15ae6",
   "metadata": {},
   "source": [
    "#### We must also find a way to remove some 'junk' data - for example, this could include the pixel value measurements from any z-slices of the image where the sample isn't there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The plots of intensity and standard deviation peak at the very beginning - comparing the relevant z-slice on your image, you can see this is where your sample comes into focus!\n",
    "So, anything from before that point is measuring noise - we can simply ignore it\n",
    "\"\"\"\n",
    "\n",
    "def find_first_peak(df):\n",
    "    y = df[\"Mean Intensity\"].values # takes all the values of y\n",
    "\n",
    "    dy = np.diff(y) # differential of y\n",
    "    peak_positions = np.where((dy[:-1] > 0) & (dy[1:] < 0))[0] + 1 # measures the first peak (where dy/dx = 0)\n",
    "\n",
    "    return df.index[peak_positions[0]]\n",
    "\n",
    "\n",
    "def normalise_start(df):\n",
    "    peak_idx = find_first_peak(df) #finds the first peak index in the data\n",
    "\n",
    "    peak_depth = df.loc[peak_idx, \"Slice\"] # uses the first peak index to find the Z slice where the sample first comes into focus\n",
    "\n",
    "    df[\"Peak Depth\"] = peak_depth\n",
    "    df[\"Aligned Depth\"] = step_size_Z*(df[\"Slice\"] - peak_depth) # removes data before the point of the sample, so the first instance of seeing your sample is Z=0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82605935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying functions to your data\n",
    "normalise_mean(df)\n",
    "normalise_std(df)\n",
    "normalise_start(df)\n",
    "\n",
    "# removing 'junk data' before the peak\n",
    "clean_data = df[df['Aligned Depth'] > 0]\n",
    "clean_data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5ff14-021f-4cc4-83be-77225657cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising results\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=clean_data,\n",
    "    x='Aligned Depth',\n",
    "    y='Normalised Mean',\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "\n",
    "sns.lineplot(\n",
    "    data=clean_data,\n",
    "    x='Aligned Depth',\n",
    "    y='Normalised Std Dev',\n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "\n",
    "axs[1].set_xlabel(\"Imaging depth (µm)\", fontsize=13)\n",
    "axs[0].set_xlabel(\"Imaging depth (µm)\", fontsize=13)\n",
    "\n",
    "axs[1].set_ylabel(\"Normalised Standard Deviation\", fontsize=13)\n",
    "axs[0].set_ylabel(\"Normalised Mean Intensity\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a5cc7",
   "metadata": {},
   "source": [
    "## **Cell detection**\n",
    "### While measuring pixel intensities is useful, it gives very little information on what *biological information* you can see, for example:\n",
    "- #### if you can detect more cells/nuclei with a cleared sample\n",
    "- #### if your sample has shrank or expanded due to a clearing protocol\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a2070",
   "metadata": {},
   "source": [
    "### 2D nuclei detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597bc340-28a0-4772-be60-70d57c7133b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise Cellpose model in our code\n",
    "model = models.Cellpose(gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23febf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nuclei detection - here, we use a library called Cellpose (a deep-learning algorithm for nuclei detection)\n",
    "\n",
    "mask_slices = []\n",
    "props_df = pd.DataFrame() #empty DataFrame to add all data to\n",
    "\n",
    "for n in range(0, len(im_nuclear)): #loops through every z-slice in your image\n",
    "    slice = im_nuclear[n]\n",
    "    \n",
    "    masks, flows, styles, diams = model.eval(slice, diameter=13, flow_threshold=2, cellprob_threshold=-1) # cell detection using cellpose\n",
    "\n",
    "    print(f\"z={n}\")\n",
    "    print(f\"Number of nuclei detected:{np.max(masks)}\")\n",
    "\n",
    "    nuclei_props = measure.regionprops_table(masks, slice, properties=['area', 'mean_intensity', 'eccentricity', 'centroid']) # uses a function to measure the properties of each nuclei detected\n",
    "    nuclei_props = pd.DataFrame(nuclei_props)\n",
    "    \n",
    "    edge_distance = distance_transform_edt(mask[n]) #calculates distance map for binary mask of sample\n",
    "    nuclei_distances = []\n",
    "\n",
    "    for idx, row in nuclei_props.iterrows(): #finds x and y centroid coordinates for each nucleus detected\n",
    "        cy = int(row['centroid-0'])\n",
    "        cx = int(row['centroid-1'])\n",
    "\n",
    "        dist = edge_distance[cy,cx] # measures the distance of each nucleus centroid from the edge (added parameter)\n",
    "        nuclei_distances.append(dist)\n",
    "        \n",
    "    nuclei_props['Slice'] = n\n",
    "    nuclei_props['nuclei_per_slice'] = np.max(masks)\n",
    "    nuclei_props['distance_from_edge'] = nuclei_distances\n",
    "\n",
    "    props_df = pd.concat([props_df, nuclei_props], ignore_index=True) # adds data from slice into DataFrame\n",
    "\n",
    "\n",
    "    slice_binmask = masks>0 \n",
    "    fig, axs= plt.subplots(1, 2, figsize=(12,8)) # plots the raw data and the detected nuclei side by side per iteration\n",
    "    \n",
    "    axs[0].imshow(slice, cmap='gray')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(slice_binmask, cmap='gray')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a172d2c-9809-403e-bc4b-5d1ae853d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "props_df['Imaging depth'] = props_df['Slice'] * z_res\n",
    "props_df['Clearing'] = 'ECi' # this is the KEY PART! change this to whichever clearing protocol you're using!\n",
    "props_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad0ab9",
   "metadata": {},
   "source": [
    "## **Normalising Cell Data**\n",
    "\n",
    "### Similar to the statistical measurements, we have to clean our cell detection data to make sure any significant differences are valid.\n",
    "### Here, we are adjusting for differences in the start of the sample, similar to before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to find the 'peak' for nuclei detections per dataset\n",
    "\n",
    "def find_nuclei_peak(df):\n",
    "    nuclei_data = df['nuclei_per_slice']\n",
    "    nuclei_data = pd.unique(nuclei_data.to_numpy()) # creates a 1D array of the detected nuclei per slice\n",
    "    \n",
    "    peaks = find_peaks(nuclei_data)\n",
    "    print(peaks)\n",
    "\n",
    "    return peaks[0][0]\n",
    "\n",
    "\n",
    "def normalise_cell_start(df):\n",
    "    peak_idx = find_nuclei_peak(df) #finds the first peak index in the data\n",
    "\n",
    "    peak_depth = df.iloc[peak_idx][\"Slice\"] # uses the first peak index to find the Z slice where the sample first comes into focus\n",
    "\n",
    "    df[\"Peak Depth\"] = peak_depth\n",
    "    df[\"Aligned Depth\"] = step_size_Z*(df[\"Slice\"] - peak_depth) # removes data before the point of the sample, so the first instance of seeing your sample is Z=0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88fbe2-7d23-46c3-ab4c-9947dc919fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to data\n",
    "normalise_cell_start(props_df)\n",
    "props_df = props_df[props_df['Aligned Depth'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97265d10-d251-49be-8ca0-b2ac96d7bd64",
   "metadata": {},
   "source": [
    "### Then, we can visualise our data to see if the results are what we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ae20f-d7f1-4f5f-9f65-d8491c65d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising data and QC\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=props_df,\n",
    "    x='Aligned Depth',\n",
    "    y='nuclei_per_slice',\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "\n",
    "sns.lineplot(\n",
    "    data=props_df,\n",
    "    x='Aligned Depth',\n",
    "    y='eccentricity',\n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=props_df,\n",
    "    x='Aligned Depth',\n",
    "    y='area',\n",
    "    ax=axs[2]\n",
    ")\n",
    "\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "axs[2].grid(True)\n",
    "\n",
    "axs[0].set_xlabel(\"Imaging depth (µm)\", fontsize=13)\n",
    "axs[1].set_xlabel(\"Imaging depth (µm)\", fontsize=13)\n",
    "axs[2].set_xlabel(\"Imaging depth (µm)\", fontsize=13)\n",
    "\n",
    "axs[0].set_ylabel(\"Nuclei detections\", fontsize=13)\n",
    "axs[1].set_ylabel(\"Nuclear eccentricity\", fontsize=13)\n",
    "axs[2].set_ylabel(\"Nuclear area (px)\", fontsize=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39cf1a1",
   "metadata": {},
   "source": [
    "## **Measuring morphology change**\n",
    "\n",
    "### Clearing protocols often shrink or expand the sample: this can be measured by comparing the are of the MIP of the sample in different conditions.\n",
    "### Luckily, we already measured this earlier! So we can just add it to our pandas DataFrame(s) to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# producing MIP from nuclear channel\n",
    "\n",
    "mip = np.max(im_nuclear, axis=0) # MIP is made by finding the max intensity at any pixel in the (X,Y) plane through Z; think of it as 'squishing' a 3D image down so only the brightest spots per pixel is left!\n",
    "\n",
    "plt.imshow(mip, cmap='gray') # visualise the MIP - this should be a single 2D image!\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the midpoint of the MIP\n",
    "\n",
    "mip_thresh = filters.threshold_li(mip) #using segmentation to identify the MIP from the background\n",
    "binary_mip = mip >= mip_thresh\n",
    "    \n",
    "clean_labels = (binary_mip > 0).astype(np.uint8)\n",
    "mip_props = measure.regionprops_table(clean_labels, mip, properties=['area']) #measures the centroid for all objects detected within the binary mask - in this case, this is just the MIP!\n",
    "\n",
    "area = round((int(mip_props['area']) * (x_res*x_res)),2) # calculates area in square µm\n",
    "\n",
    "clean_data['mip_area'] = area # saves MIP area data into dataframe\n",
    "clean_data.tail() # view the first 5 rows of data as a check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9daf757",
   "metadata": {},
   "source": [
    "## **Saving your data**\n",
    "\n",
    "### Since the data we've collected so far is stored in a pandas DataFrame, which is very similar to a .csv, we can convert it so all your data is stored in a `.csv` file!\n",
    "### This way, you can have a `.csv` file for each sample you image, and use tgem compare the clearing protocols using the parameters measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d68972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data into .csv files\n",
    "\n",
    "clean_data.to_csv(\"cal127-2B2_ECi_stats-data.csv\") # saves statistical parameters\n",
    "props_df.to_csv(\"cal127-2B2_ECi_cell-data.csv\") # saves nuclei count and QC parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f7c221",
   "metadata": {},
   "source": [
    "## **Data Analysis**\n",
    "\n",
    "### `NOTE: this can be done AFTER analysing all of your images`\n",
    "### Now you've analysed your images, you can compare them, and perform the analyses that you'd like. To get you started, this icludes:\n",
    "- ### A script to combine all of your `.csv` files together, and allow analysis\n",
    "- ### Some basic comparisons of the parameters measured "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for combining all .csv files together\n",
    "\n",
    "def combine_stats_files(folder_path):\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    print(csv_files)\n",
    "\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"Image\"] = os.path.basename(file).replace(\"_stats-data.csv\", \"\")\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Combine all\n",
    "    all_data = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def combine_cell_files(folder_path):\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    print(csv_files)\n",
    "\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"Image\"] = os.path.basename(file).replace(\"_cell-data.csv\", \"\")\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Combine all\n",
    "    all_data = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importinh all statistical data as as pandas dataframe\n",
    "stats_data = combine_stats_files(\"data/cal127/stats-data/\")\n",
    "stats_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ee0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all nuclei detection data as a pandas dataframe\n",
    "cell_data = combine_cell_files(\"data/cal127/cell-data/\")\n",
    "cell_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    data=cell_data,\n",
    "    x='Aligned Depth',\n",
    "    y='area',\n",
    "    hue='Clearing',\n",
    ")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Nuclei detected per slice\", fontsize=13)\n",
    "plt.xlabel(\"Imaging depth (µm)\", fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    data=stats_data,\n",
    "    x='Aligned Depth',\n",
    "    y='Normalised Mean',\n",
    "    hue='Clearing',\n",
    ")\n",
    "\n",
    "plt.xlim(0,)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Imaging Depth (µm)\", fontsize=12)\n",
    "plt.ylabel(\"Normalised Mean Intensity (%)\", fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
